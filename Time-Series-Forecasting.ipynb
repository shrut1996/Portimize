{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1380, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "stock = 'GOOGLE'\n",
    "symbol = 'GOOGL'\n",
    "start_date = datetime.today()+timedelta(days=-2000)\n",
    "end_date = datetime.today()\n",
    "prices = web.DataReader(symbol, 'yahoo', start_date, end_date)\n",
    "print prices.shape\n",
    "\n",
    "# Averaging the Open, High, Low, Close Prices for each day\n",
    "prices = prices.iloc[:,:4].values.mean(axis=1)\n",
    "\n",
    "# Normalizing the average price\n",
    "sc = MinMaxScaler()\n",
    "prices = sc.fit_transform(prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def structure_time_series(prices, history_size, forecast_size):\n",
    "    '''\n",
    "    Converts the time series into a structured format for training purposes\n",
    "    Days(t-history_size, t-1) will be the input variables\n",
    "    Days(t, t+forecast_size) will be the target variables\n",
    "    '''\n",
    "    \n",
    "    df = pd.DataFrame(prices)\n",
    "    features, names = [], []\n",
    "\n",
    "    for i in range(history_size, 0, -1):\n",
    "        features.append(df.shift(i))\n",
    "        names += [('day t-%d' % (i))]\n",
    "\n",
    "    for i in range(0, forecast_size):\n",
    "        features.append(df.shift(-i))\n",
    "        names += [('day t+%d' % (i))]\n",
    "        \n",
    "\n",
    "    data = pd.concat(features, axis=1)\n",
    "    data.columns = names\n",
    "    \n",
    "    # Slicing the dataframe to avoid null values\n",
    "    return data[history_size:-forecast_size+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_test_split(prices, split, history_size, forecast_size):\n",
    "    values = prices.values\n",
    "    n_train_hours = int(prices.shape[0] * split)\n",
    "    train = values[:n_train_hours, :]\n",
    "    test = values[n_train_hours:, :]\n",
    "    \n",
    "    # split into input and outputs\n",
    "    X_train, y_train = train[:, :history_size], train[:, -forecast_size-1:-1]\n",
    "    X_test, y_test = test[:, :history_size], test[:, -forecast_size-1:-1]\n",
    "    \n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "    y_train = y_train.reshape((y_train.shape[0], y_train.shape[1]))\n",
    "    y_test = y_test.reshape((y_test.shape[0], y_test.shape[1]))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_and_train_model(X_train, y_train):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(y_train.shape[1]))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1214, 1, 30), (1214, 2), (135, 1, 30), (135, 2))\n"
     ]
    }
   ],
   "source": [
    "history_size = 30\n",
    "\n",
    "##### 2-Day Forecast #####\n",
    "\n",
    "data = structure_time_series(prices, history_size, 2)\n",
    "X_train, y_train, X_test, y_test = train_test_split(data, 0.9, history_size, 2)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1092 samples, validate on 122 samples\n",
      "Epoch 1/50\n",
      "1092/1092 [==============================] - 0s 294us/step - loss: 0.0285 - val_loss: 0.0026\n",
      "Epoch 2/50\n",
      "1092/1092 [==============================] - 0s 91us/step - loss: 0.0012 - val_loss: 0.0032\n",
      "Epoch 3/50\n",
      "1092/1092 [==============================] - 0s 84us/step - loss: 8.6418e-04 - val_loss: 0.0030\n",
      "Epoch 4/50\n",
      "1092/1092 [==============================] - 0s 81us/step - loss: 7.5563e-04 - val_loss: 0.0020\n",
      "Epoch 5/50\n",
      "1092/1092 [==============================] - 0s 76us/step - loss: 7.1208e-04 - val_loss: 0.0017\n",
      "Epoch 6/50\n",
      "1092/1092 [==============================] - 0s 78us/step - loss: 6.7472e-04 - val_loss: 0.0013\n",
      "Epoch 7/50\n",
      "1092/1092 [==============================] - 0s 71us/step - loss: 6.6161e-04 - val_loss: 0.0013\n",
      "Epoch 8/50\n",
      "1092/1092 [==============================] - 0s 77us/step - loss: 6.4151e-04 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "1092/1092 [==============================] - 0s 105us/step - loss: 6.0905e-04 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "1092/1092 [==============================] - 0s 100us/step - loss: 5.9061e-04 - val_loss: 0.0017\n",
      "Epoch 11/50\n",
      "1092/1092 [==============================] - 0s 74us/step - loss: 5.8136e-04 - val_loss: 0.0012\n",
      "Epoch 12/50\n",
      "1092/1092 [==============================] - 0s 72us/step - loss: 5.4465e-04 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "1092/1092 [==============================] - 0s 74us/step - loss: 5.2476e-04 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "1092/1092 [==============================] - 0s 84us/step - loss: 5.0617e-04 - val_loss: 0.0014\n",
      "Epoch 15/50\n",
      "1092/1092 [==============================] - 0s 97us/step - loss: 4.8435e-04 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "1092/1092 [==============================] - 0s 108us/step - loss: 4.6317e-04 - val_loss: 0.0012\n",
      "Epoch 17/50\n",
      "1092/1092 [==============================] - 0s 114us/step - loss: 4.4597e-04 - val_loss: 9.7449e-04\n",
      "Epoch 18/50\n",
      "1092/1092 [==============================] - 0s 105us/step - loss: 4.1606e-04 - val_loss: 0.0012\n",
      "Epoch 19/50\n",
      "1092/1092 [==============================] - 0s 80us/step - loss: 4.0250e-04 - val_loss: 0.0012\n",
      "Epoch 20/50\n",
      "1092/1092 [==============================] - 0s 78us/step - loss: 3.8030e-04 - val_loss: 8.4913e-04\n",
      "Epoch 21/50\n",
      "1092/1092 [==============================] - 0s 71us/step - loss: 3.6630e-04 - val_loss: 9.9347e-04\n",
      "Epoch 22/50\n",
      "1092/1092 [==============================] - 0s 76us/step - loss: 3.4778e-04 - val_loss: 0.0012\n",
      "Epoch 23/50\n",
      "1092/1092 [==============================] - 0s 72us/step - loss: 3.4792e-04 - val_loss: 8.7974e-04\n",
      "Epoch 24/50\n",
      "1092/1092 [==============================] - 0s 102us/step - loss: 3.1074e-04 - val_loss: 8.7105e-04\n",
      "Epoch 25/50\n",
      "1092/1092 [==============================] - 0s 102us/step - loss: 3.0708e-04 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "1092/1092 [==============================] - 0s 98us/step - loss: 2.9115e-04 - val_loss: 7.7872e-04\n",
      "Epoch 27/50\n",
      "1092/1092 [==============================] - 0s 70us/step - loss: 2.7813e-04 - val_loss: 8.3149e-04\n",
      "Epoch 28/50\n",
      "1092/1092 [==============================] - 0s 69us/step - loss: 2.6282e-04 - val_loss: 0.0011\n",
      "Epoch 29/50\n",
      "1092/1092 [==============================] - 0s 83us/step - loss: 2.5944e-04 - val_loss: 6.9040e-04\n",
      "Epoch 30/50\n",
      "1092/1092 [==============================] - 0s 77us/step - loss: 2.6040e-04 - val_loss: 8.4435e-04\n",
      "Epoch 31/50\n",
      "1092/1092 [==============================] - 0s 73us/step - loss: 2.3818e-04 - val_loss: 7.3096e-04\n",
      "Epoch 32/50\n",
      "1092/1092 [==============================] - 0s 77us/step - loss: 2.3238e-04 - val_loss: 6.3388e-04\n",
      "Epoch 33/50\n",
      "1092/1092 [==============================] - 0s 82us/step - loss: 2.2368e-04 - val_loss: 6.4919e-04\n",
      "Epoch 34/50\n",
      "1092/1092 [==============================] - 0s 88us/step - loss: 2.2235e-04 - val_loss: 6.7079e-04\n",
      "Epoch 35/50\n",
      "1092/1092 [==============================] - 0s 81us/step - loss: 2.1565e-04 - val_loss: 6.1020e-04\n",
      "Epoch 36/50\n",
      "1092/1092 [==============================] - 0s 67us/step - loss: 2.1515e-04 - val_loss: 9.1526e-04\n",
      "Epoch 37/50\n",
      "1092/1092 [==============================] - 0s 65us/step - loss: 2.1638e-04 - val_loss: 8.2509e-04\n",
      "Epoch 38/50\n",
      "1092/1092 [==============================] - 0s 63us/step - loss: 1.9517e-04 - val_loss: 8.4334e-04\n",
      "Epoch 39/50\n",
      "1092/1092 [==============================] - 0s 63us/step - loss: 2.2594e-04 - val_loss: 5.3696e-04\n",
      "Epoch 40/50\n",
      "1092/1092 [==============================] - 0s 70us/step - loss: 1.9361e-04 - val_loss: 0.0012\n",
      "Epoch 41/50\n",
      "1092/1092 [==============================] - 0s 76us/step - loss: 2.0479e-04 - val_loss: 7.8733e-04\n",
      "Epoch 42/50\n",
      "1092/1092 [==============================] - 0s 80us/step - loss: 1.7774e-04 - val_loss: 5.3701e-04\n",
      "Epoch 43/50\n",
      "1092/1092 [==============================] - 0s 87us/step - loss: 1.7334e-04 - val_loss: 5.1791e-04\n",
      "Epoch 44/50\n",
      "1092/1092 [==============================] - 0s 96us/step - loss: 1.9250e-04 - val_loss: 5.9270e-04\n",
      "Epoch 45/50\n",
      "1092/1092 [==============================] - 0s 81us/step - loss: 1.7642e-04 - val_loss: 5.9198e-04\n",
      "Epoch 46/50\n",
      "1092/1092 [==============================] - 0s 82us/step - loss: 1.7293e-04 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "1092/1092 [==============================] - 0s 70us/step - loss: 2.0335e-04 - val_loss: 4.8497e-04\n",
      "Epoch 48/50\n",
      "1092/1092 [==============================] - 0s 77us/step - loss: 1.5474e-04 - val_loss: 5.3211e-04\n",
      "Epoch 49/50\n",
      "1092/1092 [==============================] - 0s 107us/step - loss: 1.5242e-04 - val_loss: 4.4955e-04\n",
      "Epoch 50/50\n",
      "1092/1092 [==============================] - 0s 105us/step - loss: 1.5353e-04 - val_loss: 8.1873e-04\n",
      "Test RMSE: 0.034\n"
     ]
    }
   ],
   "source": [
    "model1 = build_and_train_model(X_train, y_train)\n",
    "\n",
    "pred = model1.predict(X_test)\n",
    "rmse = math.sqrt(mean_squared_error(y_test, pred))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "model1.save('2DayForecast.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1211, 1, 30), (1211, 5), (135, 1, 30), (135, 5))\n"
     ]
    }
   ],
   "source": [
    "##### 5-Day Forecast #####\n",
    "\n",
    "data = structure_time_series(prices, history_size, 5)\n",
    "X_train, y_train, X_test, y_test = train_test_split(data, 0.9, history_size, 5)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1089 samples, validate on 122 samples\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 0s 372us/step - loss: 0.0274 - val_loss: 0.0040\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 0s 64us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 0s 65us/step - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 0s 65us/step - loss: 0.0010 - val_loss: 0.0024\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 0s 64us/step - loss: 9.6606e-04 - val_loss: 0.0021\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 0s 64us/step - loss: 9.9906e-04 - val_loss: 0.0020\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 0s 66us/step - loss: 9.0860e-04 - val_loss: 0.0019\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 0s 68us/step - loss: 8.8244e-04 - val_loss: 0.0019\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 0s 64us/step - loss: 8.6379e-04 - val_loss: 0.0018\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 0s 67us/step - loss: 8.3291e-04 - val_loss: 0.0015\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 0s 66us/step - loss: 8.0434e-04 - val_loss: 0.0016\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 0s 73us/step - loss: 7.8667e-04 - val_loss: 0.0016\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 0s 87us/step - loss: 7.6685e-04 - val_loss: 0.0015\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 0s 116us/step - loss: 7.4189e-04 - val_loss: 0.0017\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 0s 95us/step - loss: 7.1060e-04 - val_loss: 0.0014\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 0s 74us/step - loss: 6.9187e-04 - val_loss: 0.0013\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 0s 70us/step - loss: 6.7349e-04 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 0s 71us/step - loss: 6.3542e-04 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 0s 74us/step - loss: 6.3301e-04 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 0s 81us/step - loss: 5.9867e-04 - val_loss: 0.0015\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 0s 123us/step - loss: 5.7748e-04 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 0s 103us/step - loss: 6.2264e-04 - val_loss: 0.0015\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 0s 81us/step - loss: 5.4370e-04 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 0s 71us/step - loss: 5.1888e-04 - val_loss: 0.0012\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 0s 72us/step - loss: 5.0825e-04 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 0s 101us/step - loss: 5.0792e-04 - val_loss: 0.0014\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 0s 113us/step - loss: 4.6237e-04 - val_loss: 0.0013\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 0s 97us/step - loss: 4.4697e-04 - val_loss: 0.0014\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 0s 72us/step - loss: 5.7148e-04 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 0s 77us/step - loss: 4.9168e-04 - val_loss: 0.0015\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 0s 120us/step - loss: 4.3197e-04 - val_loss: 0.0012\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 0s 115us/step - loss: 4.4256e-04 - val_loss: 0.0017\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 0s 96us/step - loss: 4.1514e-04 - val_loss: 0.0020\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 0s 99us/step - loss: 4.3633e-04 - val_loss: 0.0014\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 0s 96us/step - loss: 4.0363e-04 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 0s 99us/step - loss: 4.0918e-04 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 0s 98us/step - loss: 3.8996e-04 - val_loss: 0.0012\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 0s 109us/step - loss: 3.7805e-04 - val_loss: 0.0012\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 0s 112us/step - loss: 3.9226e-04 - val_loss: 0.0011\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 0s 95us/step - loss: 3.9810e-04 - val_loss: 0.0019\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 0s 62us/step - loss: 4.0007e-04 - val_loss: 0.0012\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 0s 65us/step - loss: 4.0259e-04 - val_loss: 0.0023\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 0s 62us/step - loss: 3.8293e-04 - val_loss: 0.0011\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 0s 64us/step - loss: 3.7826e-04 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 0s 66us/step - loss: 3.9154e-04 - val_loss: 0.0016\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 0s 64us/step - loss: 3.9970e-04 - val_loss: 0.0011\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 0s 63us/step - loss: 3.5655e-04 - val_loss: 0.0011\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 0s 64us/step - loss: 3.7466e-04 - val_loss: 0.0012\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 0s 63us/step - loss: 3.5547e-04 - val_loss: 0.0012\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 0s 63us/step - loss: 3.4945e-04 - val_loss: 0.0011\n",
      "Test RMSE: 0.039\n"
     ]
    }
   ],
   "source": [
    "model2 = build_and_train_model(X_train, y_train)\n",
    "\n",
    "pred = model2.predict(X_test)\n",
    "rmse = math.sqrt(mean_squared_error(y_test, pred))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "model2.save('5DayForecast.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1206, 1, 30), (1206, 10), (135, 1, 30), (135, 10))\n"
     ]
    }
   ],
   "source": [
    "##### 10-Day Forecast #####\n",
    "\n",
    "data = structure_time_series(prices, history_size, 10)\n",
    "X_train, y_train, X_test, y_test = train_test_split(data, 0.9, history_size, 10)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1085 samples, validate on 121 samples\n",
      "Epoch 1/50\n",
      "1085/1085 [==============================] - 1s 473us/step - loss: 0.0382 - val_loss: 0.0049\n",
      "Epoch 2/50\n",
      "1085/1085 [==============================] - 0s 101us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 3/50\n",
      "1085/1085 [==============================] - 0s 96us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 4/50\n",
      "1085/1085 [==============================] - 0s 97us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 5/50\n",
      "1085/1085 [==============================] - 0s 108us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 6/50\n",
      "1085/1085 [==============================] - 0s 98us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 7/50\n",
      "1085/1085 [==============================] - 0s 84us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 8/50\n",
      "1085/1085 [==============================] - 0s 71us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 9/50\n",
      "1085/1085 [==============================] - 0s 102us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 10/50\n",
      "1085/1085 [==============================] - 0s 94us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 11/50\n",
      "1085/1085 [==============================] - 0s 97us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 12/50\n",
      "1085/1085 [==============================] - 0s 71us/step - loss: 9.9489e-04 - val_loss: 0.0022\n",
      "Epoch 13/50\n",
      "1085/1085 [==============================] - 0s 65us/step - loss: 9.8042e-04 - val_loss: 0.0020\n",
      "Epoch 14/50\n",
      "1085/1085 [==============================] - 0s 64us/step - loss: 9.5533e-04 - val_loss: 0.0022\n",
      "Epoch 15/50\n",
      "1085/1085 [==============================] - 0s 62us/step - loss: 9.4769e-04 - val_loss: 0.0023\n",
      "Epoch 16/50\n",
      "1085/1085 [==============================] - 0s 69us/step - loss: 9.1392e-04 - val_loss: 0.0020\n",
      "Epoch 17/50\n",
      "1085/1085 [==============================] - 0s 95us/step - loss: 9.0806e-04 - val_loss: 0.0019\n",
      "Epoch 18/50\n",
      "1085/1085 [==============================] - 0s 111us/step - loss: 8.8844e-04 - val_loss: 0.0018\n",
      "Epoch 19/50\n",
      "1085/1085 [==============================] - 0s 92us/step - loss: 8.6223e-04 - val_loss: 0.0017\n",
      "Epoch 20/50\n",
      "1085/1085 [==============================] - 0s 74us/step - loss: 8.5198e-04 - val_loss: 0.0020\n",
      "Epoch 21/50\n",
      "1085/1085 [==============================] - 0s 75us/step - loss: 8.4367e-04 - val_loss: 0.0016\n",
      "Epoch 22/50\n",
      "1085/1085 [==============================] - 0s 68us/step - loss: 8.1764e-04 - val_loss: 0.0017\n",
      "Epoch 23/50\n",
      "1085/1085 [==============================] - 0s 69us/step - loss: 7.9197e-04 - val_loss: 0.0019\n",
      "Epoch 24/50\n",
      "1085/1085 [==============================] - 0s 68us/step - loss: 7.6992e-04 - val_loss: 0.0023\n",
      "Epoch 25/50\n",
      "1085/1085 [==============================] - 0s 72us/step - loss: 7.5004e-04 - val_loss: 0.0016\n",
      "Epoch 26/50\n",
      "1085/1085 [==============================] - 0s 70us/step - loss: 7.4788e-04 - val_loss: 0.0021\n",
      "Epoch 27/50\n",
      "1085/1085 [==============================] - 0s 68us/step - loss: 7.1565e-04 - val_loss: 0.0017\n",
      "Epoch 28/50\n",
      "1085/1085 [==============================] - 0s 77us/step - loss: 7.0082e-04 - val_loss: 0.0021\n",
      "Epoch 29/50\n",
      "1085/1085 [==============================] - 0s 72us/step - loss: 6.9461e-04 - val_loss: 0.0017\n",
      "Epoch 30/50\n",
      "1085/1085 [==============================] - 0s 72us/step - loss: 6.7987e-04 - val_loss: 0.0023\n",
      "Epoch 31/50\n",
      "1085/1085 [==============================] - 0s 73us/step - loss: 6.8527e-04 - val_loss: 0.0023\n",
      "Epoch 32/50\n",
      "1085/1085 [==============================] - 0s 115us/step - loss: 6.5246e-04 - val_loss: 0.0019\n",
      "Epoch 33/50\n",
      "1085/1085 [==============================] - 0s 112us/step - loss: 6.4391e-04 - val_loss: 0.0021\n",
      "Epoch 34/50\n",
      "1085/1085 [==============================] - 0s 108us/step - loss: 6.3657e-04 - val_loss: 0.0019\n",
      "Epoch 35/50\n",
      "1085/1085 [==============================] - 0s 74us/step - loss: 6.1991e-04 - val_loss: 0.0016\n",
      "Epoch 36/50\n",
      "1085/1085 [==============================] - 0s 77us/step - loss: 6.2648e-04 - val_loss: 0.0017\n",
      "Epoch 37/50\n",
      "1085/1085 [==============================] - 0s 78us/step - loss: 6.0588e-04 - val_loss: 0.0017\n",
      "Epoch 38/50\n",
      "1085/1085 [==============================] - 0s 87us/step - loss: 6.0147e-04 - val_loss: 0.0017\n",
      "Epoch 39/50\n",
      "1085/1085 [==============================] - 0s 90us/step - loss: 6.0593e-04 - val_loss: 0.0017\n",
      "Epoch 40/50\n",
      "1085/1085 [==============================] - 0s 108us/step - loss: 6.0224e-04 - val_loss: 0.0017\n",
      "Epoch 41/50\n",
      "1085/1085 [==============================] - 0s 101us/step - loss: 5.9967e-04 - val_loss: 0.0018\n",
      "Epoch 42/50\n",
      "1085/1085 [==============================] - 0s 99us/step - loss: 5.8945e-04 - val_loss: 0.0020\n",
      "Epoch 43/50\n",
      "1085/1085 [==============================] - 0s 97us/step - loss: 5.7593e-04 - val_loss: 0.0019\n",
      "Epoch 44/50\n",
      "1085/1085 [==============================] - 0s 102us/step - loss: 5.6494e-04 - val_loss: 0.0017\n",
      "Epoch 45/50\n",
      "1085/1085 [==============================] - 0s 79us/step - loss: 5.7004e-04 - val_loss: 0.0022\n",
      "Epoch 46/50\n",
      "1085/1085 [==============================] - 0s 78us/step - loss: 5.5943e-04 - val_loss: 0.0021\n",
      "Epoch 47/50\n",
      "1085/1085 [==============================] - 0s 80us/step - loss: 5.6431e-04 - val_loss: 0.0019\n",
      "Epoch 48/50\n",
      "1085/1085 [==============================] - 0s 75us/step - loss: 5.8321e-04 - val_loss: 0.0018\n",
      "Epoch 49/50\n",
      "1085/1085 [==============================] - 0s 78us/step - loss: 5.4432e-04 - val_loss: 0.0021\n",
      "Epoch 50/50\n",
      "1085/1085 [==============================] - 0s 87us/step - loss: 5.4395e-04 - val_loss: 0.0023\n",
      "Test RMSE: 0.058\n"
     ]
    }
   ],
   "source": [
    "model3 = build_and_train_model(X_train, y_train)\n",
    "\n",
    "pred = model3.predict(X_test)\n",
    "rmse = math.sqrt(mean_squared_error(y_test, pred))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "model3.save('10DayForecast.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
